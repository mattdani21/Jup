{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPY4UDHr7A7Jc59/7n9T60V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3edda7d2b41f4bbda8bcb3d591d865b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_864762fb389a4b93a43386984eeb5479",
              "IPY_MODEL_5eae662fe5c24dfe80d2326a48ee0b19",
              "IPY_MODEL_169c0f3ca7ad48b7ad37f81005c90373",
              "IPY_MODEL_44bccde00ab84b348b9abf00384121ec"
            ],
            "layout": "IPY_MODEL_280d21ed0c2043c49219e4d4102126e1"
          }
        },
        "864762fb389a4b93a43386984eeb5479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_814a3243b72340f89058d86a770a9e5d",
            "placeholder": "Paste any text…",
            "rows": null,
            "style": "IPY_MODEL_b23187769c734f8bb921a7cbcb188883",
            "value": "on mars will the 2nd amendment still hold true "
          }
        },
        "5eae662fe5c24dfe80d2326a48ee0b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Classify Text",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_84c96092a9da433d9d0ffb6adbc52ca3",
            "style": "IPY_MODEL_1830d3ea89484f7893f7c3830144ff14",
            "tooltip": ""
          }
        },
        "169c0f3ca7ad48b7ad37f81005c90373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46b8831395304017a1bb1cd6389008e9"
            ],
            "layout": "IPY_MODEL_20203bae483b49a5802ed62cf366a1fe"
          }
        },
        "44bccde00ab84b348b9abf00384121ec": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a0024b67d3f143b5a119de2a0e3cad10",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "→ Predicted category: sci.space\n"
                ]
              }
            ]
          }
        },
        "280d21ed0c2043c49219e4d4102126e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814a3243b72340f89058d86a770a9e5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "600px"
          }
        },
        "b23187769c734f8bb921a7cbcb188883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84c96092a9da433d9d0ffb6adbc52ca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1830d3ea89484f7893f7c3830144ff14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "46b8831395304017a1bb1cd6389008e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 0,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".txt",
            "button_style": "",
            "data": [],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_d403c9c6d552404bb480926b358a7a72",
            "metadata": [],
            "multiple": false,
            "style": "IPY_MODEL_67be375e72b64616b8a4f3bd7a807b26"
          }
        },
        "20203bae483b49a5802ed62cf366a1fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d403c9c6d552404bb480926b358a7a72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67be375e72b64616b8a4f3bd7a807b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a0024b67d3f143b5a119de2a0e3cad10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattdani21/Jup/blob/main/Final_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Initial Setup\n",
        "\n",
        "**Sequence of Events**  \n",
        "1. Import all necessary libraries for Spark, data processing, feature engineering, modeling, and evaluation.  \n",
        "2. Initialize a Spark session running locally on all cores, named “ImprovedClassification.”\n",
        "\n",
        "## Explanation\n",
        "\t•\tImports cover Spark SQL & ML, UDFs, NumPy, scikit-learn’s dataset loader, Pandas, and plotting libs.\n",
        "\t•\tThe Spark session line boots up a local Spark cluster (using all CPU cores) for distributed data processing and ML."
      ],
      "metadata": {
        "id": "rrfd5BAyjU5N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9S0XPG6D3cPf"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import lower, regexp_replace, split, col, size\n",
        "from pyspark.ml.feature import StopWordsRemover, Word2Vec\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "from pyspark.sql.functions import udf\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"ImprovedClassification\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Definitions for Preprocessing, Embedding, and Classification\n",
        "\n",
        "This cell defines **all** of the core functions that power your end-to-end text-classification pipeline. By the end of this cell you will have:\n",
        "\n",
        "1. **Data loading & filtering**  \n",
        "2. **Text cleaning & tokenization**  \n",
        "3. **Word2Vec embedding training**  \n",
        "4. **Document vectorization (TF-weighted average of embeddings)**  \n",
        "5. **Model training** (Logistic Regression & Random Forest)  \n",
        "6. **Evaluation utilities**  \n",
        "7. **Single-string prediction helper**  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "GVeNnsbtrQ14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# Cell 2: Function definitions for preprocessing, embedding, classification\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "# Fetches five distinct 20 Newsgroups categories.\n",
        "# Removes headers, footers, quotes for cleaner text.\n",
        "# Filters out very short documents (< 10 words).\n",
        "# Wraps the result in a Spark DataFrame.\n",
        "\n",
        "def load_and_preprocess_data():\n",
        "    \"\"\"Load the 20newsgroups dataset, filter short docs, convert to Spark.\"\"\"\n",
        "    categories = [\n",
        "        'alt.atheism','comp.graphics',\n",
        "        'rec.motorcycles','sci.space','talk.politics.guns'\n",
        "    ]\n",
        "    newsgroups = fetch_20newsgroups(\n",
        "        subset='all', categories=categories,\n",
        "        remove=('headers','footers','quotes'),\n",
        "        shuffle=True, random_state=42 # ensures the same train/test split order every time you run—crucial for reproducible experiments.\n",
        "    )\n",
        "    pdf = pd.DataFrame({'text': newsgroups.data, 'label': newsgroups.target})\n",
        "    pdf = pdf[pdf['text'].str.split().str.len() >= 10] # Filtering <10 words avoids near-empty docs that can skew your Word2Vec and model training.\n",
        "    sdf = spark.createDataFrame(pdf)\n",
        "    print(f\"Loaded {sdf.count()} docs; classes = {newsgroups.target_names}\")\n",
        "    return sdf, newsgroups.target_names\n",
        "\n",
        "#\tRegex clean: strip URLs, email addresses, numbers, punctuation.\n",
        "# Lowercase & split: turn each cleaned string into a list of tokens.\n",
        "# Stop-word removal: drop common filler words (“and”, “the”, etc.).\n",
        "# Document pruning: remove docs with fewer than 5 tokens after cleaning.\n",
        "# Chaining multiple regexp_replace calls is efficient in Spark, keeping all cleaning in one pass.\n",
        "\n",
        "def advanced_text_preprocessing(df):\n",
        "    \"\"\"Clean text (URLs, emails, numbers, punctuation), tokenize, remove stop words.\"\"\"\n",
        "    df_clean = df.select(\n",
        "        'label',\n",
        "        regexp_replace(\n",
        "          regexp_replace(\n",
        "            regexp_replace(\n",
        "              regexp_replace('text', r'http\\S+|www\\S+', ''),  # remove URLs\n",
        "            r'\\S+@\\S+', ''),                                  # remove emails\n",
        "          r'\\d+', ''),                                       # remove numbers\n",
        "        r'[^\\w\\s]', ' ').alias('cleaned_text')               # remove punctuation\n",
        "    )\n",
        "    df_tokens = df_clean.select(\n",
        "        'label',\n",
        "        split(lower(col('cleaned_text')), r'\\s+').alias('tokens')\n",
        "    )\n",
        "    remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_no_stop\")\n",
        "    df_no_stop = remover.transform(df_tokens)\n",
        "    df_final = df_no_stop.filter(size(col('tokens_no_stop')) >= 5)\n",
        "    print(f\"After preprocessing: {df_final.count()} docs\")\n",
        "    return df_final.select(col('label'), col('tokens_no_stop').alias('tokens'))\n",
        "\n",
        "# Trains a Word2Vec model on your cleaned tokens with tuned hyperparameters.\n",
        "# A larger vectorSize captures richer semantic information but increases compute cost.\n",
        "# minCount=3 helps omit rare misspellings or noise.\n",
        "# numPartitions should match your local/cluster core count for best throughput.\n",
        "\n",
        "def train_improved_word2vec(df_processed):\n",
        "    \"\"\"Train Word2Vec on tokens with tuned hyperparameters.\"\"\"\n",
        "    w2v = Word2Vec(\n",
        "        vectorSize=200, minCount=3,\n",
        "        numPartitions=4, stepSize=0.05,\n",
        "        maxIter=5, windowSize=7,\n",
        "        inputCol=\"tokens\", outputCol=\"word_vectors\"\n",
        "    )\n",
        "    print(\"Training Word2Vec...\")\n",
        "    model = w2v.fit(df_processed)\n",
        "    print(f\"  Vocabulary size = {model.getVectors().count()}\")\n",
        "    return model\n",
        "\n",
        "#\tBroadcasts the trained word embeddings to all executors.\n",
        "#\tDefines a UDF tfidf_avg that computes a TF-normalized average of each document’s word vectors.\n",
        "#\tFilters out any documents that end up with a zero or null feature vector.\n",
        "#\tBroadcast avoids re-shipping the full embedding table on each task.\n",
        "#\tWe use normalized TF (count/total_tokens) rather than raw counts so longer docs don’t dominate purely by length.\n",
        "#\tReturning a zero vector for unseen words ensures the UDF never breaks but filters those docs out later.\n",
        "\n",
        "def create_document_vectors_improved(df_processed, w2v_model):\n",
        "    \"\"\"TF-normalized average of each doc’s word vectors.\"\"\"\n",
        "    vocab = {r['word']: r['vector'] for r in w2v_model.getVectors().collect()}\n",
        "    bc = spark.sparkContext.broadcast(vocab)\n",
        "    def tfidf_avg(tokens):\n",
        "        if not tokens:\n",
        "            return Vectors.dense([0.0]*200)\n",
        "        freq = {}\n",
        "        for t in tokens:\n",
        "            freq[t] = freq.get(t,0) + 1\n",
        "        total = len(tokens)\n",
        "        vecs, wts = [], []\n",
        "        for w, cnt in freq.items():\n",
        "            if w in bc.value:\n",
        "                vecs.append(bc.value[w])\n",
        "                wts.append(cnt/total)\n",
        "        if not vecs:\n",
        "            return Vectors.dense([0.0]*200)\n",
        "        arr, wts = np.array(vecs), np.array(wts)\n",
        "        wts = wts / wts.sum()\n",
        "        avg = np.average(arr, axis=0, weights=wts)\n",
        "        return Vectors.dense(avg)\n",
        "    vectorize_udf = udf(tfidf_avg, VectorUDT())\n",
        "    df_feats = df_processed.withColumn(\"features\", vectorize_udf(col(\"tokens\")))\n",
        "    df_feats = df_feats.filter(col(\"features\").isNotNull())\n",
        "    print(f\"Created vectors for {df_feats.count()} docs\")\n",
        "    return df_feats.select('label', 'features')\n",
        "\n",
        "#\tSplits your data 80/20 into train and test sets using randomSplit([.8, .2], seed=42).\n",
        "#\tTrains two models:\n",
        "   # Logistic Regression with L2 (regParam=0.01) + some L1 (elasticNetParam=0.1) regularization.\n",
        "   # Random Forest with 50 trees, max depth 10 (seeded for reproducibility).\n",
        "#\tThe fixed seed=42 ensures you always get the same train/test partition.\n",
        "#\tstandardization=True in LR scales your features to mean 0, SD 1; important when mixing TF-averaged vectors.\n",
        "def train_improved_classifier(df_features):\n",
        "    \"\"\"Train Logistic Regression & Random Forest.\"\"\"\n",
        "    train_df, test_df = df_features.randomSplit([0.8,0.2], seed=42)\n",
        "    print(f\"Train/test sizes = {train_df.count()}/{test_df.count()}\")\n",
        "\n",
        "    lr = LogisticRegression(\n",
        "        featuresCol='features', labelCol='label',\n",
        "        maxIter=100, regParam=0.01,\n",
        "        elasticNetParam=0.1, standardization=True\n",
        "    )\n",
        "    print(\"Fitting Logistic Regression...\")\n",
        "    lr_model = lr.fit(train_df)\n",
        "\n",
        "    rf = RandomForestClassifier(\n",
        "        featuresCol='features', labelCol='label',\n",
        "        numTrees=50, maxDepth=10, seed=42\n",
        "    )\n",
        "    print(\"Fitting Random Forest...\")\n",
        "    rf_model = rf.fit(train_df)\n",
        "\n",
        "    return lr_model, rf_model, train_df, test_df\n",
        "\n",
        "#\tFor each model, computes:\n",
        "  #\tAccuracy\n",
        "  #\tF1 score\n",
        "  #\tWeighted precision\n",
        "  # Weighted recall\n",
        "#\tDisplays a few sample predictions for manual inspection.\n",
        "\n",
        "#\tUsing the same evaluator for all metrics simplifies the code.\n",
        "#\tWeighted metrics account for class imbalances by averaging per-class scores weighted by support.\n",
        "def evaluate_models(models, test_df, target_names):\n",
        "    \"\"\"Print accuracy, F1, precision, recall, plus sample predictions.\"\"\"\n",
        "    for name, mdl in models.items():\n",
        "        print(f\"\\n=== {name} ===\")\n",
        "        preds = mdl.transform(test_df)\n",
        "        for m in ['accuracy','f1','weightedPrecision','weightedRecall']:\n",
        "            ev = MulticlassClassificationEvaluator(\n",
        "                labelCol='label', predictionCol='prediction', metricName=m\n",
        "            )\n",
        "            print(f\"{m}: {ev.evaluate(preds):.4f}\")\n",
        "        preds.select('label','prediction').show(5)\n",
        "\n",
        "#\tWraps a single raw string in a one-row DataFrame.\n",
        "# Applies the same preprocessing → vectorization pipeline.\n",
        "#\tRuns your chosen classifier and returns the human-readable category name.\n",
        "def predict_new_text(\n",
        "    raw_text: str,\n",
        "    w2v_model,\n",
        "    classifier_model,\n",
        "    preprocess_fn,\n",
        "    vectorize_fn,\n",
        "    target_names: list\n",
        ") -> str:\n",
        "    \"\"\"Preprocess → vectorize → predict a single string.\"\"\"\n",
        "    from pyspark.sql import Row\n",
        "    df = spark.createDataFrame([Row(text=raw_text, label=0)])\n",
        "    toks = preprocess_fn(df)\n",
        "    feats = vectorize_fn(toks, w2v_model)\n",
        "    pred = classifier_model.transform(feats).select(\"prediction\").first()[0]\n",
        "    return target_names[int(pred)]\n",
        "\n",
        "#\tThe dummy label=0 is never used but required to satisfy the schema.\n",
        "#\tBy reusing your existing functions, this helper guarantees consistent text handling between training and inference.\n",
        "#\tConsider adding a fallback or probability threshold check to handle extremely short or out-of-vocabulary inputs.\n"
      ],
      "metadata": {
        "id": "u9NwyC1u3zRW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This cell bundles together all of your data-prep, embedding, modeling, and inference steps into reusable functions.  By structuring your code this way, you achieve:**\n",
        "\n",
        "\t- Modularity: Easily tweak one component (e.g. try a different embedding or classifier) without rewriting the entire notebook.\n",
        "\t- Reproducibility: Seeds (42) and consistent cleaning/tokenization ensure experiments can be reliably rerun.\n",
        "\t- Scalability: Spark’s distributed operations (broadcasts, UDFs, ML pipelines) let you handle much larger corpora with minimal changes."
      ],
      "metadata": {
        "id": "1JfEDq3mcjAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 3: Main Pipeline Runner & Expose Models for Interactive Use\n",
        "\n",
        "This cell ties together all of your previously defined functions into a single execution flow—and ensures the trained models and label list live in your notebook namespace for later use (e.g. interactive widgets).\n",
        "\n",
        "---\n",
        "\n",
        "## What we’re accomplishing\n",
        "\n",
        "1. **Orchestrating the full pipeline**  \n",
        "   - **Load & preprocess** the data  \n",
        "   - **Train** the Word2Vec embeddings  \n",
        "   - **Create** document feature vectors  \n",
        "   - **Train** two classifiers (Logistic Regression & Random Forest)  \n",
        "   - **Evaluate** their performance on the test set  \n",
        "\n",
        "2. **Exposing key objects**  \n",
        "   - Returns (`lr_model`, `rf_model`, `w2v_model`, `target_names`) so you can call `predict_new_text` or build interactive UIs without retraining.\n",
        "\n",
        "---\n",
        "\n",
        "#Extra Notes\n",
        "\t•\tReproducibility: Using seed=42 and consistent preprocessing functions ensures the pipeline yields the same results on each run.\n",
        "\t•\tPerformance considerations: Running main() trains large models—avoid re-running this cell unless you need to retrain.\n",
        "\t•\tNamespace availability: By binding word2vec_model and lr_model at the global level, any later cell (like your widget code) can use these without causing NameError.\n",
        "\t•\tSeparation of concerns: Keeping the orchestration in main() makes it easy to reuse individual components in isolation (e.g., for batch inference or hyperparameter tuning)."
      ],
      "metadata": {
        "id": "V-zoKGhvfwUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# Cell 3: Main pipeline runner & expose models for interactive use\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "def main():\n",
        "    print(\"=== IMPROVED TEXT CLASSIFICATION MODEL ===\\n\")\n",
        "    sdf, target_names = load_and_preprocess_data()\n",
        "    proc = advanced_text_preprocessing(sdf)\n",
        "    w2v_model = train_improved_word2vec(proc)\n",
        "    feats = create_document_vectors_improved(proc, w2v_model)\n",
        "    lr_model, rf_model, _, test_df = train_improved_classifier(feats)\n",
        "    evaluate_models({'LR': lr_model, 'RF': rf_model}, test_df, target_names)\n",
        "    return lr_model, rf_model, w2v_model, target_names\n",
        "\n",
        "# Run everything once to populate globals:\n",
        "lr_model, rf_model, word2vec_model, target_names = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq3Ew6sc9488",
        "outputId": "888eb443-43a9-482a-ef3c-88d0d16592ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== IMPROVED TEXT CLASSIFICATION MODEL ===\n",
            "\n",
            "Loaded 4405 docs; classes = ['alt.atheism', 'comp.graphics', 'rec.motorcycles', 'sci.space', 'talk.politics.guns']\n",
            "After preprocessing: 4401 docs\n",
            "Training Word2Vec...\n",
            "  Vocabulary size = 14601\n",
            "Created vectors for 4401 docs\n",
            "Train/test sizes = 3575/826\n",
            "Fitting Logistic Regression...\n",
            "Fitting Random Forest...\n",
            "\n",
            "=== LR ===\n",
            "accuracy: 0.8729\n",
            "f1: 0.8724\n",
            "weightedPrecision: 0.8725\n",
            "weightedRecall: 0.8729\n",
            "+-----+----------+\n",
            "|label|prediction|\n",
            "+-----+----------+\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "=== RF ===\n",
            "accuracy: 0.8596\n",
            "f1: 0.8589\n",
            "weightedPrecision: 0.8600\n",
            "weightedRecall: 0.8596\n",
            "+-----+----------+\n",
            "|label|prediction|\n",
            "+-----+----------+\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       4.0|\n",
            "+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*This cell provides a simple in‐notebook user interface so you can drop in any text—or upload a plain .txt file—and immediately see which category your model assigns.*\n",
        "⸻\n",
        "\n",
        "#What We’re Accomplishing\n",
        "\t1.\tUI Elements\n",
        "\t•\tTextArea: a multi‐line box for pasting or typing arbitrary text.\n",
        "\t•\tButton: labeled “Classify Text” to trigger the prediction.\n",
        "\t•\tFileUpload: allows selecting a single .txt file for bulk text input.\n",
        "\t•\tOutput: an area to display the prediction result.\n",
        "\t2.\tCallbacks\n",
        "\t•\ton_btn\n",
        "\t•\tReads whatever is in the TextArea.\n",
        "\t•\tIf empty, prompts the user to paste text first.\n",
        "\t•\tOtherwise, calls your predict_new_text helper and prints the predicted category.\n",
        "\t•\ton_upload\n",
        "\t•\tListens for a file selection.\n",
        "\t•\tReads the file’s contents, decodes to string.\n",
        "\t•\tRuns the same predict_new_text helper and prints the result along with the filename.\n",
        "\t3.\tDisplay Logic\n",
        "\t•\tAll UI elements are arranged vertically for clarity.\n",
        "\t•\tThe TextArea and Button sit above the output area, with the FileUpload alongside.\n",
        "\n",
        "⸻\n",
        "\n",
        "#Key Details & Notes\n",
        "\t•\tReusing the Pipeline: This cell leverages your existing preprocessing, embedding, and classification functions—ensuring consistency between training and inference.\n",
        "\t•\tNo Retraining: Neither callback retrains any models; they simply apply the already‐trained word2vec_model and lr_model to new inputs.\n",
        "\t•\tUser Feedback:\n",
        "\t•\tIf the TextArea is blank, the button callback reminds you to paste something before classification.\n",
        "\t•\tPredictions are displayed in the Output widget, keeping notebook logs clean.\n",
        "\t•\tFlexibility:\n",
        "\t•\tPaste a single sentence, a paragraph, or upload a 1 KB text file—any input format supported.\n",
        "\t•\tYou can extend this by adding dropdowns to choose between Logistic Regression vs. Random Forest, or to adjust thresholds for custom fallback rules.\n",
        "\t•\tAvoiding NameErrors: Because word2vec_model, lr_model, and target_names were bound as globals in Cell 3, this interactive cell finds them without errors.\n"
      ],
      "metadata": {
        "id": "-utgW4dcgue4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# Cell 4: Interactive tester (paste or upload .txt)\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "from ipywidgets import Textarea, FileUpload, Button, Output, VBox, HBox\n",
        "from IPython.display import display\n",
        "\n",
        "text_area = Textarea(\n",
        "    placeholder='Paste any text…',\n",
        "    layout={'width':'600px','height':'150px'}\n",
        ")\n",
        "btn = Button(description=\"Classify Text\")\n",
        "uploader = FileUpload(accept='.txt', multiple=False)\n",
        "out = Output()\n",
        "\n",
        "def on_btn(b):\n",
        "    out.clear_output()\n",
        "    txt = text_area.value.strip()\n",
        "    if not txt:\n",
        "        with out: print(\"Paste some text first!\")\n",
        "        return\n",
        "    pred = predict_new_text(\n",
        "        raw_text=txt,\n",
        "        w2v_model=word2vec_model,\n",
        "        classifier_model=lr_model,\n",
        "        preprocess_fn=advanced_text_preprocessing,\n",
        "        vectorize_fn=create_document_vectors_improved,\n",
        "        target_names=target_names\n",
        "    )\n",
        "    with out: print(f\"→ Predicted category: {pred}\")\n",
        "\n",
        "def on_upload(change):\n",
        "    out.clear_output()\n",
        "    for name, info in uploader.value.items():\n",
        "        txt = info['content'].decode('utf-8')\n",
        "        pred = predict_new_text(\n",
        "            raw_text=txt,\n",
        "            w2v_model=word2vec_model,\n",
        "            classifier_model=lr_model,\n",
        "            preprocess_fn=advanced_text_preprocessing,\n",
        "            vectorize_fn=create_document_vectors_improved,\n",
        "            target_names=target_names\n",
        "        )\n",
        "        with out: print(f\"File “{name}” → {pred}\")\n",
        "\n",
        "btn.on_click(on_btn)\n",
        "uploader.observe(on_upload, names='value')\n",
        "\n",
        "display(VBox([text_area, btn, HBox([uploader]), out]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485,
          "referenced_widgets": [
            "3edda7d2b41f4bbda8bcb3d591d865b3",
            "864762fb389a4b93a43386984eeb5479",
            "5eae662fe5c24dfe80d2326a48ee0b19",
            "169c0f3ca7ad48b7ad37f81005c90373",
            "44bccde00ab84b348b9abf00384121ec",
            "280d21ed0c2043c49219e4d4102126e1",
            "814a3243b72340f89058d86a770a9e5d",
            "b23187769c734f8bb921a7cbcb188883",
            "84c96092a9da433d9d0ffb6adbc52ca3",
            "1830d3ea89484f7893f7c3830144ff14",
            "46b8831395304017a1bb1cd6389008e9",
            "20203bae483b49a5802ed62cf366a1fe",
            "d403c9c6d552404bb480926b358a7a72",
            "67be375e72b64616b8a4f3bd7a807b26",
            "a0024b67d3f143b5a119de2a0e3cad10"
          ]
        },
        "id": "wSJhsZXv4OKe",
        "outputId": "8685fb6c-7d91-4db9-bbb9-84b82d2043c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created vectors for 1 docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Textarea(value='', layout=Layout(height='150px', width='600px'), placeholder='Paste any text…')…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3edda7d2b41f4bbda8bcb3d591d865b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After preprocessing: 1 docs\n",
            "Created vectors for 1 docs\n",
            "After preprocessing: 1 docs\n",
            "Created vectors for 1 docs\n",
            "After preprocessing: 1 docs\n",
            "Created vectors for 1 docs\n",
            "After preprocessing: 1 docs\n",
            "Created vectors for 1 docs\n",
            "After preprocessing: 1 docs\n",
            "Created vectors for 1 docs\n",
            "After preprocessing: 1 docs\n",
            "Created vectors for 1 docs\n"
          ]
        }
      ]
    }
  ]
}